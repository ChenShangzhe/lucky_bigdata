# 监控多个目录下多个文件，支持断点续传

# Name the components on this agent
a4.sources = r4
a4.sinks = k4
a4.channels = c4


# Describe/configure the source
a4.sources.r4.type = TAILDIR
a4.sources.r4.filegroups = f1 f2
a4.sources.r4.filegroups.f1 = /data/1.txt
a4.sources.r4.filegroups.f2 = /data/2.txt
a4.sources.r4.positionFile = /data/position/position.json


# Describe the sink
a4.sinks.k4.type = hdfs
a4.sinks.k4.hdfs.path = hdfs://slave1:8020/flume/%Y%m%d/%H
# 上传文件的前缀
a4.sinks.k4.hdfs.filePrefix = logs-
# 是否按照时间滚动文件夹
a4.sinks.k4.hdfs.round = true
# 多少时间创建一个新的文件夹
a4.sinks.k4.hdfs.roundValue = 1
# 重新定义时间单位
a4.sinks.k4.hdfs.roundUnit = hour
# 是否使用本地时间戳
a4.sinks.k4.hdfs.useLocalTimeStamp = true
# 积攒多少个Event才flush到HDFS一次
a4.sinks.k4.hdfs.batchSize = 90
# 设置文件类型，可支持压缩
a4.sinks.k4.hdfs.fileType = DataStream
# 多久生成一个新文件
a4.sinks.k4.hdfs.rollInterval = 30
# 设置每个文件到滚动大小
a4.sinks.k4.hdfs.rollSize = 134217700
# 文件到滚动和Event数量无关
a4.sinks.k4.hdfs.rollCount = 0


# Use a channel which buffers events in memory
a4.channels.c4.type = memory
a4.channels.c4.capacity = 1000
a4.channels.c4.transactionCapacity = 100


# Bind the source and sink to the channel
a4.sources.r4.channels = c4
a4.sinks.k4.channel = c4