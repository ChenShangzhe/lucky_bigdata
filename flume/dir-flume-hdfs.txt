# 监控目录下多个文件，不支持断点续传
#=
# Name the components on this agent
a3.sources = r3
a3.sinks = k3
a3.channels = c3


# Describe/configure the source
a3.sources.r3.type = spooldir
a3.sources.r3.spoolDir = /data/dir
a3.sources.r3.fileSuffiex = .COMPLETED
a3.sources.r3.fileHeader = true
# 忽略以.tmp结尾的文件
a3.sources.r3.ignorePattern = ([^ ]*\.tmp)


# Describe the sink
a3.sinks.k3.type = hdfs
a3.sinks.k3.hdfs.path = hdfs://slave1:8020/flume/%Y%m%d/%H
# 上传文件的前缀
a3.sinks.k3.hdfs.filePrefix = logs-
# 是否按照时间滚动文件夹
a3.sinks.k3.hdfs.round = true
# 多少时间创建一个新的文件夹
a3.sinks.k3.hdfs.roundValue = 1
# 重新定义时间单位
a3.sinks.k3.hdfs.roundUnit = hour
# 是否使用本地时间戳
a3.sinks.k3.hdfs.useLocalTimeStamp = true
# 积攒多少个Event才flush到HDFS一次
a3.sinks.k3.hdfs.batchSize = 90
# 设置文件类型，可支持压缩
a3.sinks.k3.hdfs.fileType = DataStream
# 多久生成一个新文件
a3.sinks.k3.hdfs.rollInterval = 30
# 设置每个文件到滚动大小
a3.sinks.k3.hdfs.rollSize = 134217700
# 文件到滚动和Event数量无关
a3.sinks.k3.hdfs.rollCount = 0


# Use a channel which buffers events in memory
a3.channels.c3.type = memory
a3.channels.c3.capacity = 1000
a3.channels.c3.transactionCapacity = 100


# Bind the source and sink to the channel
a3.sources.r3.channels = c3
a3.sinks.k3.channel = c3